# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
# You can also use your global OpenAI API key if it's already set in your environment
OPENAI_API_KEY=${OPENAI_API_KEY:-your-openai-api-key-here}

# Model Configuration (Optional - these are the defaults)
LLM_MODEL=gpt-4o-mini
DISTIL_MODEL=${LLM_MODEL}  # Deprecated, use LLM_MODEL instead
ASR_MODEL=whisper-1

# Reasoning Model Configuration
# Set to true/1 if using reasoning models (o1-preview, o1-mini, etc.)
# When true, skips temperature and uses reasoning-compatible parameters
IS_REASONING_MODEL=false

# API Settings (Optional)
OPENAI_TIMEOUT=60
MAX_RETRIES=3

# LLM Behavior Configuration
# These settings control how the LLM processes requests and handles reasoning models

# Reasoning Model Settings
# Controls the effort level for reasoning models (when temperature is not supported)
# Values: minimal, low, medium, high
# Default: low (good balance of speed and quality)
REASONING_EFFORT=low

# Response Verbosity Level
# Controls how detailed LLM responses should be
# Values: low, medium, high
# Default: medium (balanced output)
# Note: Automatically adjusted based on request type (reconciliation uses lower, distillation uses higher)
VERBOSITY=medium

# Model Temperature
# Controls randomness in model responses (for standard models)
# Range: 0.0 (deterministic) to 2.0 (very creative)
# Default: 0.2 (slightly deterministic, good for code tasks)
# Note: Automatically removed when reasoning models are detected
MODEL_TEMPERATURE=0.2

# Debug Settings
# Enable detailed logging of LLM requests and responses
# Values: 0 (disabled), 1 (enabled)
# Default: 0 (logs saved to .prompt_distil/debug/ when enabled)
PD_DEBUG=0

# Configuration Examples for Different Use Cases:
#
# Fast Development (minimal processing, quick responses):
# REASONING_EFFORT=minimal
# VERBOSITY=low
# MODEL_TEMPERATURE=0.1
# PD_DEBUG=0
#
# Production (balanced performance and quality):
# REASONING_EFFORT=low
# VERBOSITY=medium
# MODEL_TEMPERATURE=0.2
# PD_DEBUG=0
#
# Detailed Analysis (thorough processing, detailed output):
# REASONING_EFFORT=high
# VERBOSITY=high
# MODEL_TEMPERATURE=0.1
# PD_DEBUG=1
#
# Creative Exploration (more varied responses):
# REASONING_EFFORT=medium
# VERBOSITY=high
# MODEL_TEMPERATURE=0.7
# PD_DEBUG=1

# Usage Instructions:
# 1. Copy this file to .env: cp .env.example .env
# 2. Replace 'your-openai-api-key-here' with your actual OpenAI API key
#    OR ensure OPENAI_API_KEY is set in your global environment
# 3. Optionally modify the LLM behavior settings based on your needs
# 4. The system will automatically handle reasoning model compatibility
#    by detecting errors and adjusting parameters as needed
